{"version":1,"state":{"f1e91fc9-4122-4df3-8f32-eb2ca9c1772e":{"id":"f1e91fc9-4122-4df3-8f32-eb2ca9c1772e","space":"shared","tags":{"creator":"34c3c210-5bf1-49cf-b151-ee2d07f0e673","_ai_extractPDFText":"@// used to extract the text from a given pdf file, before returning it as one big string\r\n\r\nconsole.log('loading pdfjs...');\r\nconst pdfjs = await import('https://cdn.jsdelivr.net/npm/pdfjs-dist@4.0.379/+esm');\r\nconsole.log('pdfjs:', pdfjs);\r\n\r\npdfjs.GlobalWorkerOptions.workerSrc = 'https://cdn.jsdelivr.net/npm/pdfjs-dist@4.0.379/build/pdf.worker.mjs';\r\n\r\nconsole.log('loading tesseract...');\r\nconst tesseract = await import(\"https://cdn.jsdelivr.net/npm/tesseract.js@5.0.4/+esm\");\r\nconsole.log('tesseract:', tesseract);\r\n\r\nconst worker = await tesseract.createWorker('eng');\r\nconsole.log('worker:', worker);\r\n\r\nconst pdf = await pdfjs.getDocument({\r\n    data: that.data,\r\n    // disableFontFace: true,\r\n}).promise;\r\nconsole.log('pdf:', pdf);\r\n\r\nconst pageCount = pdf.numPages;\r\n\r\nconst canvas = new OffscreenCanvas(512, 512);\r\nconst context = canvas.getContext('2d');\r\n\r\n// let outputHtml = `<h1>${that.name} Text Content</h1>`;\r\n\r\nlet masterString = \"\";\r\nfor (let i = 1; i <= pageCount; i++) {\r\n    os.showHtml(`Parsing ${that.name} page #${i}...`);\r\n\r\n    const page = await pdf.getPage(i);\r\n    console.log(`page ${i}:`, page);\r\n\r\n    const scale = 2;\r\n    const viewport = page.getViewport({ scale: scale, });\r\n    canvas.width = viewport.width;\r\n    canvas.height = viewport.height;\r\n\r\n    const renderContext = {\r\n        canvasContext: context,\r\n        viewport: viewport\r\n    };\r\n\r\n    // Render the page to the offscreen canvas context.\r\n    await page.render(renderContext).promise;\r\n\r\n    const blob = await canvas.convertToBlob({ type: 'image/png' });\r\n\r\n    // os.download(blob, 'test.png', 'image/png');\r\n    const result = await worker.recognize(blob, undefined, 'text');\r\n    console.log('result:', result);\r\n\r\n    masterString += result.data.text;\r\n\r\n    // outputHtml += `<h2>Page ${i}</h2>`;\r\n    // outputHtml += `<p style=\"white-space: pre\">${result.data.text}</p>`;\r\n}\r\n\r\nos.hideHtml();\r\n// os.showHtml(outputHtml);\r\n\r\nreturn masterString;","_ai_getActionResponse":"@// used to determine what rhetoric bot should do while in action mode\r\n\r\n// creates the prompt for the ai to determine what course of action to go with.\r\nlet actionPrompt = `Determine from the following message if a user wants any of the following options carried out: `;\r\nactionPrompt += ` PDF interpretation, 2D image generation, or other. User message: \"`;\r\nactionPrompt += that.message;\r\nactionPrompt += `\" Respond with a one word response corresponding to what they want:`\r\nactionPrompt += ` \"PDF\" for pdf interpretation,`;\r\nactionPrompt += ` \"IMG\" for 2D image generation,`;\r\nactionPrompt += ` or \"AB1\" for some other action.`\r\nactionPrompt += ` If a user wants you to make something for them, unless the mention making a picture or image, assume they don't want a 2D image.`\r\nactionPrompt += ` Anything other than a single word response that is \"PDF\", \"IMG\" or \"AB1\" is considered a failure.`\r\n\r\n// gets the action type from the ai model interpretting the user message\r\nlet actionType = await ai.chat(actionPrompt, {\r\n    preferredModel: tags.aiModel\r\n});\r\n\r\nconsole.log(\"action mode response: \", actionType);\r\n\r\nswitch (actionType) {\r\n    case \"PDF\":\r\n        thisBot.interpretPDF();\r\n        break;\r\n    case \"IMG\": // currently disabled from image generation until the ai.generateImage function is fixed.\r\n        thisBot.postMessage({ \"message\": \"Image generation is temporarily disabeled due to an issue. We hope to have the issue fixed soon.\", \"publicMessage\": false })\r\n        // thisBot.postMessage({ \"message\": \"Generating image...\", \"publicMessage\": false });\r\n        // const imageAddress = await ai.generateImage({\r\n        //     prompt: message,\r\n        // });\r\n        // const angle = Math.random() * 2 * Math.PI;\r\n        // const radius = 5;\r\n\r\n        // create({\r\n        //     space: \"shared\",\r\n        //     home: true,\r\n        //     homeX: (radius * Math.cos(angle)) + tags.homeX,\r\n        //     homeY: (radius * Math.sin(angle)) + tags.homeY,\r\n        //     scaleZ: 0.01,\r\n        //     scaleX: 3,\r\n        //     scaleY: 3,\r\n        //     formAddress: imageAddress\r\n        // })\r\n        break;\r\n    case \"AB1\":\r\n        let askBot = getBot(byTag(\"system\", \"ab.action.ask\"))\r\n        askBot.abCoreMenuAction({ message: that.message, menu: \"core\" });\r\n        break;\r\n}","_ai_getPDFNeurons":"@// used to turn the extracted text from a pdf file into FGB neurons to be a part of RB's memory\r\nlet topicPrompt = `You are an AI agent learning and adding topics to a force graph representation of your brain.`;\r\ntopicPrompt += `Here is the text of a pdf called ${that.name} given by a user: ${that.text}.`;\r\ntopicPrompt += ` Only Give me ONLY an array of objects to add to your knowledge pool based on the text of that pdf, with each object in the array matching the format of:`;\r\ntopicPrompt += ` [ { \"topic\": \"example_1\", \"linkedTopics\": [], \"stemConnected\": true, \"details\": \"details_string1\" }, { \"topic\": \"example_2\", \"linkedTopics\": [\"example_1\"], \"stemConnected\": false, \"details\": \"details_string2\" } ],`;\r\ntopicPrompt += ` where stemConnected is whether the topic extracted from the message should be connected to the core of your knowledge or not, and details is a string with details of the topic from the provided information.`;\r\ntopicPrompt += ` There should be at least one object with the name of the pdf, and all of the other objects in the array should be linked to that pdf name object.`;\r\ntopicPrompt += ` All topics should have at least one connection.`;\r\ntopicPrompt += ` Giving anything other than a javascript array of objects as described above is considered a failure.`;\r\n\r\nconsole.log(\"topic gathering prompt:\", topicPrompt);\r\n\r\nlet topicResponse = await ai.chat(topicPrompt, {\r\n    preferredModel: tags.aiModel\r\n})\r\n\r\nconsole.log(\"raw topicResponse\", topicResponse);\r\n\r\nreturn JSON.parse(topicResponse);","_ai_getResponse":"@let knowledgeBase = tags.knowledgeBase ?? [];\r\n\r\n// gets the ai chat response to a user's message in the chat\r\nlet responsePrompt = `You are an AI agent that responds to prompts only using information contained inside of your knowledge base: `;\r\nresponsePrompt += JSON.stringify(knowledgeBase);\r\nresponsePrompt += `. Respond to the following message from ${that.user}: \"${that.message}\".`;\r\n// responsePrompt += ``;\r\n\r\nlet responseResponse = await ai.chat(responsePrompt, {\r\n    preferredModel: tags.aiModel\r\n});\r\n\r\nconsole.log(\"raw responseResponse\", responseResponse);\r\n\r\nreturn responseResponse;","_ai_getSubjects":"@let knowledgeBase = tags.knowledgeBase ?? [];\r\n\r\n// takes a given user message and uses it to determine what information RB should add to itself\r\nlet topicPrompt = `You are an AI agent with the following knowledge base: `;\r\ntopicPrompt += JSON.stringify(knowledgeBase);\r\ntopicPrompt += ` And here is a message sent by ${that.user} in a chat you're in: \"${that.message}\".`;\r\ntopicPrompt += ` Only give me an array of objects to add to your knowledge base based on their message, with each object in the array matching the format of:`;\r\ntopicPrompt += ` [ { \"topic\": \"example_1\", \"linkedTopics\": [], \"stemConnected\": true, \"details\": \"example details 1\" }, { \"topic\": \"example_2\", \"linkedTopics\": [\"example_1\"], \"stemConnected\": false, \"details\": \"example details 2\" } ],`;\r\ntopicPrompt += ` where stemConnected is whether the topic extracted from the message should be connected to the core of your knowledge or not, and details are strings of accopanying details for that topic found within the message.`;\r\ntopicPrompt += ` All topics should have at least one connection, either to other topics or to your information core.`;\r\ntopicPrompt +=  ` It is acceptable to return an empty array if there is no new information to be added. Keep topics in your knowledge base broad, and avoid having more than 32 topics inside of your knowledge base.`\r\ntopicPrompt += ` Example 1: Your knowledge base is empty, and a user named Jimmy sends the message \"I have a cat and a dog as my pets. I also like to run around with my dog, climb, and play baseball.\" An appropriate response object would be:`\r\ntopicPrompt += ` [{ \"topic\": \"pets\", \"linkedTopics\": [], \"stemConnected\": true, \"details\": \"Jimmy has a pet cat and a pet dog.\" }, { \"topic\": \"physical activity\", \"linkedTopics\": [\"pets\"], \"stemConnected\": true, \"details\": \"Jimmy likes to climb and play baseball, as well as run with his dog.\" }].`\r\ntopicPrompt += ` Example 2: Your knowledge base contains: [{ \"topic\": \"gardening\", \"linkedTopics\": [\"hobbies\"], \"stemConnected\": false, \"details\": \"Mrs. Walters likes to garden on the weekends.\" }, { \"topic\": \"hobbies\", \"linkedTopics\": [], \"stemConnected\": true, \"details\": \"Mrs. Walters has lots of hobbies, like fishing and doing puzzles.\" }].`\r\ntopicPrompt += ` A user named Mr. Walters sends the message: \"My wife, Mrs. Walters, and I are going on a fishing trip this weekend.\" An appropritate response object would be: [{ \"topic\": \"traveling\", \"linkedTopics\": [\"hobbies\"], \"stemConnected\": true, \"details\": \"Mr and Mrs Walters are going to be going on a fishing trip soon.\" }].`\r\ntopicPrompt += ` Giving anything other than a javascript array of objects as described above is considered a failure.`;\r\n\r\nconsole.log(\"topic gathering prompt:\", topicPrompt);\r\n\r\nlet topicResponse = await ai.chat(topicPrompt, {\r\n    preferredModel: tags.aiModel\r\n})\r\n\r\nconsole.log(\"raw topicResponse\", topicResponse);\r\n\r\nreturn JSON.parse(topicResponse);","_ai_getUpdatedDetails":"@let knowledgeBase = tags.knowledgeBase ?? [];\r\n\r\n// used to get any information a neuron should be updated with from user messages\r\nlet detailsPrompt = `You are an AI agent with the following knowledge base: `;\r\ndetailsPrompt += JSON.stringify(knowledgeBase);\r\ndetailsPrompt += ` And here is a message sent by ${that.user} in a chat you're in: \"${that.message}\".`;\r\ndetailsPrompt += ` Only give me an array of objects to update your knowledge pool based on their message, with each object in the array matching the format of:`;\r\ndetailsPrompt += ` [ { \"topic\": \"example_1\", \"details\": \"example details 1\" }, { \"topic\": \"example_2\", \"details\": \"example details 2\" } ],`;\r\ndetailsPrompt += ` where \"topic\" is an existing topic you know, and \"details\" are the updated details of that topic, based on new information obtained from the user's message`;\r\ndetailsPrompt += ` You are allowed to return an empty array if there are not any new details to add to a topic. Details provided in each object should be noticeably updated with new information.`\r\ndetailsPrompt += ` Example: Your knowledge base includes the object { \"topic\": \"pets\", \"details\": \"Jimmy has a pet dog and a pet cat.\" }. Jimmy then sends the message, \"My dog Rosey scared my cat Rob today by jumping around.\"`;\r\ndetailsPrompt += ` An appropriate response object would be: [{ \"topic\": \"pets\", \"details\": \"Jimmy has a pet dog named Rosey and a pet cat named Rob. Rosey likes to jump around, which sometimes scares Rob.\" }].`\r\ndetailsPrompt += `Returning anything other than an object array that follows the rules described is considered a failure.`;\r\n\r\nconsole.log(\"updating details prompt:\", detailsPrompt);\r\n\r\nlet detailsResponse = await ai.chat(detailsPrompt, {\r\n    preferredModel: tags.aiModel\r\n})\r\n\r\nconsole.log(\"raw detailsResponse\", detailsResponse);\r\n\r\nreturn JSON.parse(detailsResponse);","_ai_interpretPDF":"@// used to run the whole process of turning a pdf file into a knowledge inside of rb's brain\r\nthisBot._console_postMessage({ \"message\": \"Please submit the PDF.\", \"publicMessage\": false });\r\n\r\nawait os.sleep(3000);\r\n\r\nconst files = await os.showUploadFiles();\r\nconsole.log('files:', files);\r\n\r\nlet pdfFile = null;\r\n\r\nfor (let file of files) {\r\n    if (file.mimeType === 'application/pdf') {\r\n        pdfFile = file;\r\n        break;\r\n    }\r\n}\r\n\r\nif (!pdfFile) {\r\n    thisBot._console_postMessage({ \"message\": \"I'm sorry, that file wasn't a PDF.\", \"publicMessage\": false });\r\n    return;\r\n}\r\n\r\nconsole.log('pdfFile:', pdfFile);\r\n\r\nlet pdfString = await thisBot._ai_extractPDFText(pdfFile);\r\nconsole.log(\"pdf string\", pdfString);\r\n\r\nthisBot._menu_rbThinking(true);\r\n\r\nlet pdfNeurons = await thisBot._ai_getPDFNeurons({ name: pdfFile.name, text: pdfString });\r\n\r\nconsole.log(\"pdfNeurons\", pdfNeurons);\r\n\r\nthisBot._brain_createFGBNeurons({ neuronMods: pdfNeurons, neuronsColor: \"white\" });\r\n\r\nthisBot._console_postMessage({ \"message\": \"Memory updated with PDF information.\", \"publicMessage\": true });\r\n\r\nthisBot._menu_rbThinking(false);\r\n\r\nif (humeSocket) {\r\n    await os.sleep(10);\r\n\r\n    let knowledgeBase = tags.knowledgeBase ?? [];\r\n\r\n    const systemSettings = JSON.stringify(knowledgeBase);\r\n    console.log(\"allowed_topics:\", systemSettings)\r\n\r\n    humeSocket.send(JSON.stringify({\r\n        \"type\": \"session_settings\",\r\n        \"variables\": {\r\n            \"allowed_topics\": systemSettings,\r\n        }\r\n    }));\r\n}","_ai_learnResponse":"@let knowledgeBase = tags.knowledgeBase ?? [];\r\n\r\n// takes a given user message and uses it to determine what information RB should add to itself\r\nlet topicPrompt = `You are an AI agent with the following knowledge base: `;\r\ntopicPrompt += JSON.stringify(knowledgeBase);\r\ntopicPrompt += ` And here is a message sent by ${that.user} in a chat you're in: \"${that.message}\".`;\r\ntopicPrompt += ` Your task is to update your knowledge base based on this message and return a single JSON object with the following structure:`;\r\ntopicPrompt += ` {\r\n  \"add\": [ { \"topic\": string, \"linkedTopics\": string[], \"stemConnected\": boolean, \"details\": string } ],\r\n  \"merge\": [ { \"newName\": string, \"topicsToMerge\": string[] } ],\r\n  \"update\": [ { \"topic\": string, \"details\": string } ],\r\n  \"remove\": string[]\r\n}.`;\r\ntopicPrompt += ` \r\nRules and details:\r\n- \"add\" contains new topics inferred from the message.\r\n- \"merge\" contains topics that should be combined into a broader or more appropriate single topic.\r\n- \"update\" contains existing topics that should have their details refreshed or expanded.\r\n- \"remove\" contains topic names that are outdated, redundant, or contradicted by new information.\r\n- Each added topic must connect to at least one other topic or the knowledge core.\r\n- You may leave any of the four arrays empty.\r\n- Avoid exceeding 32 total topics in your knowledge base.\r\n- Avoid putting underscores in topic names.`;\r\n\r\ntopicPrompt += ` \r\n\r\nExample 1:\r\nKnowledge base: (empty)\r\nMessage: \"I have a cat and a dog as my pets. I also like to run around with my dog, climb, and play baseball.\"\r\nResponse object:\r\n{\r\n  \"add\": [\r\n    { \"topic\": \"pets\", \"linkedTopics\": [], \"stemConnected\": true, \"details\": \"Jimmy has a pet cat and a pet dog.\" },\r\n    { \"topic\": \"physical activity\", \"linkedTopics\": [\"pets\"], \"stemConnected\": true, \"details\": \"Jimmy likes to climb and play baseball, as well as run with his dog.\" }\r\n  ],\r\n  \"merge\": [],\r\n  \"update\": [],\r\n  \"remove\": []\r\n}`;\r\n\r\ntopicPrompt += ` \r\n\r\nExample 2:\r\nKnowledge base: [\r\n  { \"topic\": \"gardening\", \"linkedTopics\": [\"hobbies\"], \"stemConnected\": false, \"details\": \"Mrs. Walters likes to garden on the weekends.\" },\r\n  { \"topic\": \"fishing\", \"linkedTopics\": [\"hobbies\"], \"stemConnected\": false, \"details\": \"Mrs. Walters enjoys fishing during the summer.\" },\r\n  { \"topic\": \"traveling\", \"linkedTopics\": [], \"stemConnected\": true, \"details\": \"The Walters occasionally take short trips.\" },\r\n  { \"topic\": \"hobbies\", \"linkedTopics\": [], \"stemConnected\": true, \"details\": \"Mrs. Walters has many hobbies, like gardening and fishing.\" }\r\n]\r\nMessage: \"My wife and I are combining our love for gardening and fishing into a new YouTube channel about outdoor adventures. We won’t be doing as many small weekend trips anymore, but we’ll travel for filming instead.\"\r\nResponse object:\r\n{\r\n  \"add\": [\r\n    { \"topic\": \"YouTube channel\", \"linkedTopics\": [\"gardening\", \"fishing\", \"traveling\"], \"stemConnected\": true, \"details\": \"The Walters are starting a YouTube channel about outdoor adventures.\" }\r\n  ],\r\n  \"merge\": [\r\n    { \"newName\": \"outdoor activities\", \"topicsToMerge\": [\"gardening\", \"fishing\"] }\r\n  ],\r\n  \"update\": [\r\n    { \"topic\": \"traveling\", \"details\": \"The Walters will now travel mainly for filming their YouTube channel instead of taking small weekend trips.\" }\r\n  ],\r\n  \"remove\": [\"weekend trips\"]\r\n}`;\r\n\r\ntopicPrompt += ` \r\n\r\nGiving anything other than a JSON object with \"add\", \"merge\", \"update\", and \"remove\" arrays as described above is considered a failure.`;\r\n\r\n\r\nconsole.log(\"topic gathering prompt:\", topicPrompt);\r\n\r\ntry {\r\n  let learnResponse = await ai.chat(topicPrompt, {\r\n    preferredModel: tags.aiModel\r\n  })\r\n\r\n  console.log(\"raw learnResponse\", learnResponse);\r\n\r\n  let parsedResponse = JSON.parse(learnResponse);\r\n  parsedResponse.success = true;\r\n\r\n  return parsedResponse;\r\n}\r\ncatch {\r\n  console.error(\"AI Chat Error.\")\r\n  return { success: false }\r\n}","_audio_clearQueues":"@// used to clear the audio and text queues when a user interupts the hume ai audio chat\r\nthisBot.masks.audioQueue && thisBot.masks.audioQueue.length > 0 ? thisBot.masks.audioQueue.length = 1 : null;\r\nthisBot.masks.textQueue && thisBot.masks.textQueue.length > 0 ? thisBot.masks.textQueue.length = 1 : null;\r\n\r\nos.cancelSound(thisBot.masks.activeSound);\r\n\r\nthisBot.masks.activeSound = null;","_audio_endAudioChat":"@// trigger when ending audio chat with hume ai\r\n\r\nconsole.log(\"audio chat end\");\r\nmasks.audioChat = false;\r\nshout(\"resetACLabel\");\r\n\r\nconst humeSocket = thisBot.vars.humeSocket;\r\n\r\nif(humeSocket) {\r\n    humeSocket.close(1000, 'User ended the chat');\r\n    delete thisBot.vars.humeSocket;\r\n}\r\n\r\ntry {\r\n    await os.endAudioRecording();\r\n} catch(e) {\r\n    console.warn(e);\r\n}","_audio_playQueuedAudio":"@console.log(\"playQueuedAudio triggered\", thisBot.vars.playingQueue)\r\n\r\nif (thisBot.vars.playingQueue)\r\n{\r\n    return;\r\n}\r\n\r\nthisBot.vars.playingQueue = true;\r\n\r\nwhile (thisBot.masks.audioQueue.length > 0)\r\n{\r\n    const activeAudio = thisBot.masks.audioQueue[0];\r\n    const activeText = thisBot.masks.textQueue[0];\r\n\r\n    thisBot.masks.audioQueue.splice(0, 1);\r\n    thisBot.masks.textQueue.splice(0,1);\r\n    if(thisBot.vars.playHumeAudio == true){\r\n        let soundId = os.playSound(activeAudio);\r\n        thisBot.masks.activeSound = soundId;\r\n        ab.log({ message: activeText, name: tags.name, space: \"shared\", rbIgnoreMessage: true, rbProcessMessage: true, messageOrigin: configBot.id });\r\n        \r\n        await os.sleep((getDuration(activeAudio) * 1000));\r\n        \r\n        thisBot.masks.activeSound = null;\r\n    }\r\n\r\n    // os.playSound(activeAudio);\r\n    // thisBot.masks.audioQueue.splice(0, 1);\r\n    // await os.sleep((getDuration(activeAudio) * 1000) + 500);\r\n\r\n    console.log(\"AUDIO QUEUE: \", thisBot.masks.audioQueue);\r\n}\r\n\r\nthisBot.vars.playingQueue = null;\r\n\r\nfunction base64ToArrayBuffer(base64) {\r\n    const binaryString = self.atob(base64.split(',')[1]);\r\n    const bytes = Uint8Array.from(binaryString, char => char.charCodeAt(0));\r\n    return bytes.buffer;\r\n}\r\n\r\nfunction getWavDuration(arrayBuffer) {\r\n    const view = new DataView(arrayBuffer);\r\n\r\n    // Check the \"RIFF\" identifier\r\n    if (view.getUint32(0, false) !== 0x52494646) {\r\n        throw new Error(\"Invalid WAV file\");\r\n    }\r\n\r\n    // Check the \"WAVE\" identifier\r\n    if (view.getUint32(8, false) !== 0x57415645) {\r\n        throw new Error(\"Invalid WAV file\");\r\n    }\r\n\r\n    // Get the byte rate from the fmt subchunk\r\n    const byteRate = view.getUint32(28, true);\r\n\r\n    // Get the total number of bytes in the data subchunk\r\n    const dataChunkSize = view.getUint32(40, true);\r\n\r\n    // Calculate duration\r\n    const duration = dataChunkSize / byteRate;\r\n\r\n    return duration;\r\n}\r\n\r\nfunction getDuration(base64) {\r\n    var arrBuffer = base64ToArrayBuffer(base64);\r\n    return getWavDuration(arrBuffer);\r\n}\r\n\r\n","_audio_queueAudio":"@// Required Parameters\r\nconst base64Audio = that;\r\n\r\n// Optional Parameters\r\n\r\nconst mimeType = \"audio/wav\"; // Adjust MIME type as needed\r\nconst dataURL = `data:${mimeType};base64,${base64Audio}`;\r\n\r\n// os.playSound(dataURL);\r\n\r\n// const audioObject = { audio: dataURL, timestamp: os.isCollaborative() ? os.agreedUponTime : os.localTime }\r\n\r\nthisBot.masks.audioQueue = thisBot.masks.audioQueue ? [...thisBot.masks.audioQueue].concat(dataURL) : [dataURL];\r\n\r\nthisBot._audio_playQueuedAudio();\r\n\r\n// console.log(\"audio queue:\",thisBot.masks.audioQueue)","_audio_queueText":"@// Required Parameters\r\nconst text = that;\r\n\r\nthisBot.masks.textQueue = thisBot.masks.textQueue ? [...thisBot.masks.textQueue].concat(text) : [text];","_audio_startAudioChat":"@// trigger when starting audio chat with hume\r\n\r\nconsole.log(\"audio chat start\");\r\nmasks.audioChat = \"loading\";\r\nshout(\"resetACLabel\");\r\n\r\nconst endpoint = \"wss://api.hume.ai/v0/evi/chat\";\r\nconst accessToken = (await ai.hume.getAccessToken()).accessToken;\r\nconst configID = \"e04b02d5-cb78-4292-aba4-a912d8926ddd\";\r\n\r\nconst url = new URL(endpoint);\r\nurl.searchParams.set(\"access_token\", accessToken);\r\nurl.searchParams.set(\"config_id\", configID);\r\n\r\nawait os.beginAudioRecording({\r\n    stream: true,\r\n    mimeType: 'audio/wav'\r\n});\r\n\r\nconst humeSocket = new WebSocket(url.toString());\r\nthisBot.vars.humeSocket = humeSocket;\r\nthisBot.vars.playingQueue = false;\r\n\r\nlet knowledgeBase = tags.knowledgeBase ?? [];\r\n\r\nconst session_settings = {\r\n    \"type\": \"session_settings\",\r\n    \"variables\": {\r\n        \"name\": tags.name,\r\n        \"allowed_topics\": JSON.stringify(knowledgeBase),\r\n    }\r\n};\r\n\r\nhumeSocket.addEventListener('open', (event) => {\r\n    console.warn(\"Hume Socket opened: \", event);\r\n    // shout(\"onHumeWebSocketOpened\", event);\r\n    humeSocket.send(JSON.stringify(session_settings));\r\n\r\n    thisBot._audio_clearQueues();\r\n\r\n    if ([\"learning\", \"whisper\", \"shout\"].includes(tags.currentMode)) {\r\n        thisBot.vars.playHumeAudio = true;\r\n    }\r\n});\r\n\r\nhumeSocket.addEventListener('close', (event) => {\r\n    console.warn(\"Hume Socket closed: \", event);\r\n    thisBot._audio_endAudioChat();\r\n    // shout(\"onHumeChatEnded\", event);\r\n});\r\n\r\nhumeSocket.addEventListener('message', async (event) => {\r\n    const data = JSON.parse(event.data);\r\n\r\n    console.log(\"blueb\", data);\r\n\r\n    if (data.type == \"audio_output\") {\r\n        if ([\"learning\", \"whisper\", \"shout\"].includes(tags.currentMode)) {\r\n            thisBot._audio_queueAudio(data.data);\r\n        }\r\n    }\r\n    else if (data.type == \"assistant_message\") {\r\n        if ([\"learning\", \"whisper\", \"shout\"].includes(tags.currentMode) && thisBot.vars.playHumeAudio == true) {\r\n            const message = data.message.content;\r\n            thisBot._audio_queueText(message);\r\n            // ab.log({ message: message, name: tags.name, space: \"shared\", rbIgnoreMessage: true });\r\n        }\r\n    }\r\n    else if (data.type == \"error\") {\r\n        console.warn('error: ', data.message);\r\n    }\r\n    else if (data.type == \"user_message\") {\r\n        let username = \"user\";\r\n\r\n        if (authBot && authBot.tags.name && authBot.tags.name != \"\") {\r\n            username = authBot.tags.name;\r\n        } else if (ab.links.console.masks.preferredName) {\r\n            username = ab.links.console.masks.preferredName;\r\n        } else {\r\n            username = await os.showInput(\"\", {\r\n                title: \"What would you like me to call you?\"\r\n            });\r\n            ab.links.console.masks.preferredName = username;\r\n        }\r\n\r\n        const message = data.message.content;\r\n\r\n        ab.log({\r\n            message: message,\r\n            name: username,\r\n            space: \"shared\",\r\n            rbIgnoreMessage: tags.currentMode != \"learning\",\r\n            audioInput: true,\r\n            messageOrigin: configBot.id,\r\n            rbProcessMessage: tags.currentMode == \"learning\"\r\n        });\r\n\r\n        // thisBot.clearQueues();\r\n\r\n        if([\"learning\", \"whisper\", \"shout\"].includes(tags.currentMode)){\r\n            thisBot.vars.playHumeAudio = true;\r\n        }\r\n    }\r\n    else if (data.type == \"tool_call\") {\r\n        console.log(\"Tool called: \", data.name, data);\r\n        if(data.name == \"read_pdf\"){\r\n            thisBot._ai_interpretPDF();\r\n        }\r\n    }\r\n    else if (data.type == \"user_interruption\") {\r\n        thisBot._ai_clearQueues();\r\n\r\n        if ([\"learning\", \"whisper\", \"shout\"].includes(tags.currentMode)) {\r\n            thisBot.vars.playHumeAudio = true;\r\n        }\r\n    }\r\n    else {\r\n        console.log(\"unexpected message:\", data.type, data);\r\n    }\r\n});","_brain_createFGBNeurons":"@let knowledgeBase = tags.knowledgeBase ?? [];\r\nknowledgeBase = JSON.parse(JSON.stringify(knowledgeBase));\r\n\r\nconsole.log(\"knowledgeBase:\", knowledgeBase);\r\n\r\nlet neuronBots = [];\r\n\r\nlet baseNeuron = {\r\n    space: \"tempLocal\",\r\n    system: \"msRhetoricBot.neuron\",\r\n    home: true,\r\n    stemID: thisBot.id,\r\n    forceGraph: 'fg' + thisBot.id,\r\n    linkTopics: `@ let links = shout(\"linkCheck\", tags.linkedTopics); tags.stemConnected == true ? links.push(tags.stemID) : null; tags.lineTo = links ?? [];`,\r\n    linkCheck: `@ if(that.includes(tags.topic)){ return thisBot.id; };`,\r\n    removeNeuronBots: `@ destroy(thisBot);`,\r\n    form: \"circle\",\r\n    orientationMode: \"billboard\",\r\n    labelPosition: \"floatingBillboard\",\r\n    labelWordWrapMode: \"none\",\r\n    onPointerEnter: `@ \r\n            let tipID = await os.tip(tags.details, null, null, 120);\r\n            masks.tipID = tipID;\r\n        `,\r\n    onPointerExit: `@ os.hideTips(masks.tipID);`\r\n};\r\n\r\nlet existingNeurons = getBots(byTag(\"system\", \"msRhetoricBot.neuron\"));\r\nif (existingNeurons.length == 0) {\r\n    for (const neuron of knowledgeBase) {\r\n        let extraTags = {\r\n            label: neuron.topic,\r\n            topic: neuron.topic,\r\n            linkedTopics: [...neuron.linkedTopics],\r\n            stemConnected: neuron.stemConnected,\r\n            details: neuron.details,\r\n            homeX: tags.homeX + 20*(Math.random()-0.5),\r\n            homeY: tags.homeY + 20*(Math.random()-0.5)\r\n        }\r\n        neuronBots.push({...baseNeuron, ...extraTags})\r\n    }\r\n\r\n    // console.log(neuronBots);\r\n    create(neuronBots);\r\n    shout(\"linkTopics\");\r\n}\r\n\r\ntags.forceGraph = 'fg' + thisBot.id;\r\ntags.fgSettings = {\"gravity\":false,\"linkDistance\":3,\"dimensions\":3};\r\n\r\nawait os.sleep(150);\r\nsimManager.start(tags.forceGraph);","_brain_updateKnowledge":"@let knowledgeBase = tags.knowledgeBase ?? [];\r\nknowledgeBase = JSON.parse(JSON.stringify(knowledgeBase));\r\n\r\nlet {\r\n  add,\r\n  update,\r\n  merge,\r\n  remove\r\n} = that || {};\r\n\r\nconsole.log(\"knowledgeBase:\", knowledgeBase);\r\n\r\nknowledgeBase.push(...add); // adds new neurons\r\n\r\nknowledgeBase = updateMatchingObjects(knowledgeBase, update); // updates existing neurons\r\n\r\n// merges neurons, marks the ones being merged for removal\r\nfor (const mergedNeuron of merge) {\r\n  let newName = mergedNeuron.newName;\r\n  let topicsToMerge = mergedNeuron.topicsToMerge;\r\n  let mergedDetails = \"\";\r\n  let stemConnected = false;\r\n  let connections = [];\r\n\r\n  for (const index in knowledgeBase) {\r\n    let neuron = knowledgeBase[index];\r\n    if (topicsToMerge.includes(neuron.topic)) {\r\n      mergedDetails.length == 0 ? null : mergedDetails += \" \";\r\n      mergedDetails += neuron.details;\r\n      neuron.stemConnected == true ? stemConnected = true : null;\r\n      connections.push(...neuron.linkedTopics);\r\n    }\r\n\r\n    neuron.linkedTopics = replaceArrayOverlaps(neuron.linkedTopics, topicsToMerge, newName);\r\n\r\n  }\r\n\r\n  connections = connections.filter(e => !topicsToMerge.includes(e));\r\n  connections = [...new Set(connections)];\r\n\r\n  knowledgeBase.push({\r\n    \"topic\": newName,\r\n    \"linkedTopics\": connections,\r\n    \"stemConnected\": stemConnected,\r\n    \"details\": mergedDetails\r\n  })\r\n\r\n  remove.push(...topicsToMerge)\r\n}\r\n\r\nknowledgeBase = knowledgeBase.filter(e => !remove.includes(e.topic)); //removes topics in the remove array\r\n\r\n// cleans up neuron linkedTopics properties of removed neurons\r\nfor (const neuron of knowledgeBase) {\r\n  neuron.linkedTopics = neuron.linkedTopics.filter(e => !remove.includes(e))\r\n}\r\n\r\ntags.knowledgeBase = knowledgeBase; // updates the knowledge base with final array\r\n\r\n// finds overlaps between arr1 and arr2 and replaces them in arr1 with the provided newValue\r\nfunction replaceArrayOverlaps(arr1, arr2, newValue) {\r\n  const overlap = arr1.filter(v => arr2.includes(v));\r\n  const replaced = arr1.map(v => overlap.includes(v) ? newValue : v);\r\n  return [...new Set(replaced)];\r\n}\r\n\r\n// updates the details of the neurons\r\nfunction updateMatchingObjects(targetArray, updatesArray, matchKey = \"topic\", updateKey = \"details\", targetProp = \"details\") {\r\n  const updatesMap = new Map(updatesArray.map(obj => [obj[matchKey], obj[updateKey]]));\r\n\r\n  return targetArray.map(obj => {\r\n    if (updatesMap.has(obj[matchKey])) {\r\n      return { ...obj, [targetProp]: updatesMap.get(obj[matchKey]) };\r\n    }\r\n    return obj;\r\n  });\r\n}\r\n\r\nlet neuronBots = getBots(byTag(\"system\", \"msRhetoricBot.neuron\"));\r\nif (neuronBots.length > 0) {\r\n  shout(\"removeNeuronBots\");\r\n  thisBot._brain_createFGBNeurons();\r\n}","_console_onSubmit":"@if (!ab.links.console.masks.open) {\r\n    whisper(ab.links.console, \"showConsole\");\r\n    ab.links.console.masks.open = true;\r\n}\r\n\r\nlet username = \"user\";\r\n\r\nif (authBot && authBot.tags.name && authBot.tags.name != \"\") {\r\n    username = authBot.tags.name;\r\n} else if (ab.links.console.masks.preferredName) {\r\n    username = ab.links.console.masks.preferredName;\r\n} else {\r\n    username = await os.showInput(\"\", {\r\n        title: \"What would you like me to call you?\"\r\n    });\r\n    ab.links.console.masks.preferredName = username;\r\n}\r\n\r\nmasks.menuItemText = \"\";\r\n\r\n\r\nab.log({message: that.text, name: username, space: \"shared\", rbIgnoreMessage: that.rbIgnoreMessage, messageOrigin: configBot.id, rbProcessMessage: true});","_console_onSubmitPrivate":"@if (!ab.links.console.masks.open) {\r\n    whisper(ab.links.console, \"showConsole\");\r\n    ab.links.console.masks.open = true;\r\n}\r\n\r\nlet username = \"user\";\r\n\r\nif (authBot && authBot.tags.name && authBot.tags.name != \"\") {\r\n    username = authBot.tags.name;\r\n} else if (ab.links.console.masks.preferredName) {\r\n    username = ab.links.console.masks.preferredName;\r\n} else {\r\n    username = await os.showInput(\"\", {\r\n        title: \"What would you like me to call you?\"\r\n    });\r\n    ab.links.console.masks.preferredName = username;\r\n}\r\n\r\nmasks.menuItemText = \"\";\r\n\r\nab.links.input.onChat({ message: that.text, rbIgnoreMessage: that.rbIgnoreMessage, messageOrigin: configBot.id, rbProcessMessage: true });\r\nab.log({ message: that.text, name: username, space: \"tempLocal\", rbIgnoreMessage: that.rbIgnoreMessage, messageOrigin: configBot.id, rbProcessMessage: true });","_console_openABConsole":"@if (!ab.links.console.masks.open) {\r\n    whisper(ab.links.console, \"showConsole\");\r\n    ab.links.console.masks.open = true;\r\n}\r\n\r\nconst menuPortal = configBot.tags.menuPortal ?? \"rbInput\";\r\n\r\nif (!configBot.tags.menuPortal)\r\n{\r\n    configBot.tags.menuPortal = menuPortal;\r\n}\r\n\r\nconfigBot.tags.menuPortal = \"rbChatMenu\";","_console_postMessage":"@if (!ab.links.console.masks.open) {\r\n    whisper(ab.links.console, \"showConsole\");\r\n    ab.links.console.masks.open = true;\r\n}\r\n\r\nlet username = tags.name;\r\n\r\nmasks.menuItemText = \"\";\r\n\r\nif (that.publicMessage == true) {\r\n    ab.log({message: that.message, name: username, space: \"shared\", rbProcessMessage: true, messageOrigin: configBot.id});\r\n} else {\r\n    ab.links.input.onChat({message: that.message});\r\n    ab.log({message: that.message, name: username, space: \"tempLocal\", rbProcessMessage: true, messageOrigin: configBot.id});\r\n}","_debug_clearBrain":"@tags.knowledgeBase = null;","_debug_clearLog":"@// debug tool for resetting the rhetoric bot back to a starting state with the assistance of some helper bots\r\nif (ab.links.console.masks.open) {\r\n    whisper(ab.links.console, \"hideConsole\");\r\n    ab.links.console.masks.open = null;\r\n}\r\n\r\nconst menuPortal = configBot.tags.menuPortal ?? \"menu\";\r\nmasks[menuPortal] = false;","_debug_resetRB":"@whisper(thisBot, \"clearBrain\");\r\nwhisper(thisBot, \"clearLog\");\r\ntags.brainLink = null;\r\nshout(\"resetRBMenu\");\r\ntags.neuronCopy = null;\r\ntags.forceGraph = null;\r\ntags.fgSettings = null;\r\ntags.homeX = 0;\r\ntags.homeY = 0;\r\ntags.homeZ = 0;","_debug_startRB":"@thisBot.onEggHatch();","_fg_importForceGraph":"@console.log(\"importing msForceGraphTool\")\r\n\r\n// const forceGraphToolBot = getBot(byTag('abIDOrigin', 'msForceGraphTool'))\r\nconst forceGraphToolBot = getBot(byTag(\"system\", \"ms-forceGraph.init\"))\r\n\r\nconsole.log(\"forceGraphTool bot found: \", !!forceGraphToolBot, forceGraphToolBot);\r\n\r\nif (!forceGraphToolBot) {\r\n    // await shout(\"hatch\", {abID: \"msForceGraphTool\", recordKey: \"6db28ddc-1835-4fb4-8ed3-5ccf26c02217\", autoHatch: true, eggParameters: {defaultBots: false, abIgnore: true}});\r\n\r\n    ab.links.search.onLookupAskID({\r\n        askID: \"fgTool\",\r\n        eggParameters: {\r\n            toolboxBot: tags.toolbox ?? \"\",\r\n            gridInformation: tags.gridInformation,\r\n            defaultBots: false\r\n        },\r\n    })\r\n}","_fg_updateFGSettings":"@tags.fgSettings = {\"gravity\":false,\"linkDistance\":3,\"dimensions\":3};","_menu_rbThinking":"@shout(\"rbThinkingReset\");\r\nconfigBot.tags.menuPortal = \"rbMenu\";\r\n\r\nif (that == true) {\r\n    let thinkingMods = {\r\n        space: \"tempLocal\",\r\n        rbMenu: true,\r\n        rbMenuBot: true,\r\n        rbThinkingBot: true,\r\n        pairedRB: getLink(thisBot),\r\n        rbMenuSortOrder: 0,\r\n        rbThinkingReset: `@ destroy(thisBot)`,\r\n        color: \"#50E2F2\",\r\n        trackNum: 0,\r\n        labelAlignment: \"center\",\r\n        onCreate: `@\r\n                if(tags.styleModApplied == false){\r\n                let existingStyle = tags.menuItemStyle;\r\n                console.log(\"existingStyle\", existingStyle);\r\n                existingStyle.width = \"300px\";\r\n                existingStyle[\"align-self\"] = \"center\"\r\n                tags.menuItemStyle = existingStyle;\r\n                tags.styleModApplied = true;\r\n            }\r\n\r\n            if (tags.trackNum == 2)\r\n            {\r\n                tags.trackNum = 0;\r\n            }\r\n            else\r\n            {\r\n                tags.trackNum++;\r\n            }\r\n\r\n            tags.label = tags[\"label\"+tags.trackNum];\r\n            tags.formAddress = tags[\"form\"+tags.trackNum];\r\n\r\n            setTimeout(() => whisper(thisBot, \"onCreate\"), 500);`,\r\n        label0: thisBot.tags.name + ` is thinking.`,\r\n        label1: thisBot.tags.name + ` is thinking..`,\r\n        label2: thisBot.tags.name + ` is thinking...`,\r\n        form0: \"hourglass_bottom\",\r\n        form1: \"hourglass_top\",\r\n        form2: \"hourglass_bottom\",\r\n        loading: true,\r\n        styleModApplied: false,\r\n        system: \"rbMenuBot.thinking\",\r\n    };\r\n\r\n    if (!ab.links.menu) {\r\n        // Load abInterface skill if ab.links.menu is not available.\r\n        await ab.abAdapt('abInterface');\r\n    }\r\n\r\n    await ab.links.menu.abCreateMenuButton(thinkingMods);\r\n}\r\nelse if(that == false){\r\n    let remotes = await os.remotes();\r\n    sendRemoteData(remotes, \"stopThinking\");\r\n}","_menu_setRBMenuState":"@if (!ab.links.menu) {\r\n    // Load abInterface skill if ab.links.menu is not available.\r\n    await ab.abAdapt('abInterface');\r\n}\r\n\r\nshout(\"resetRBMenu\");\r\n\r\nconst state = typeof that == \"string\" ? that : undefined;\r\nconst baseMenuMods = {\r\n    space: \"tempLocal\",\r\n    rbMenu: true,\r\n    rbMenuBot: true,\r\n    color: \"white\",\r\n    pairedRB: getLink(thisBot),\r\n    resetRBMenu: `@ destroy(thisBot)`,\r\n}\r\nconst menuItems = [];\r\n\r\nswitch (state) {\r\n    // case \"chatInput\":\r\n    //     let inputMods = {\r\n    //         form: \"input\",\r\n    //         formAddress: \"edit\",\r\n    //         label: \"Chat with everyone!\",\r\n    //         system: \"rbMenuBot.input\",\r\n    //         rbMenuSortOrder: 1,\r\n    //         onSubmit: tags.onSubmit\r\n    //     };\r\n    //     menuItems.push({ ...baseMenuMods, ...inputMods });\r\n    //     break;\r\n    case \"mainMenu\":\r\n        let modeDisplay = tags.currentMode == \"learning\" ? \"learn\" :\r\n            tags.currentMode == \"whisper\" ? \"direct message\" :\r\n                tags.currentMode == \"shout\" ? \"chat with everyone\" :\r\n                    tags.currentMode == \"sleep\" ? \"sleep\" : \"unknown\"\r\n        let rbModeMods = {\r\n            formAddress: \"arrow_right\",\r\n            label: `cb mode: ${modeDisplay}`,\r\n            // resetLabel: `@ \r\n            //     let mode\r\n            //     switch(getTag(links.pairedRB, \"currentMode\")){\r\n            //         case \"learning\":\r\n            //             mode = \"learn\";\r\n            //             break;\r\n            //         case \"whisper\":\r\n            //             mode = \"direct message\";\r\n            //             break;\r\n            //         case \"shout\":\r\n            //             mode = \"chat with everyone\";\r\n            //             break;\r\n            //         case \"action\":\r\n            //             mode = \"action\";\r\n            //             break;\r\n            //         default:\r\n            //             mode = \"sleep\";\r\n            //             break;\r\n            //     }\r\n            //     tags.label = \"cb mode: \" + mode\r\n            // `,\r\n            system: \"rbMenuBot.rbMode\",\r\n            rbMenuSortOrder: 1,\r\n            dropdownSortOrder: 1,\r\n            dropdownOptions: [\r\n                {\r\n                    label: \"sleep\",\r\n                    mode: \"sleep\",\r\n                    pairedRB: getLink(thisBot),\r\n                    system: \"rbMenuBot.sleepMode\",\r\n                    color: \"white\",\r\n                    onClick: `@ \r\n                        setTag(links.pairedRB, \"currentMode\", \"sleep\"); \r\n                        links.pairedRB._menu_setRBMenuState(\"mainMenu\");\r\n                        links.pairedRB._utility_updateVar({ varName: \"playHumeAudio\", varValue: false });\r\n                    `\r\n                },\r\n                {\r\n                    label: \"learn\",\r\n                    mode: \"learning\",\r\n                    pairedRB: getLink(thisBot),\r\n                    system: \"rbMenuBot.learningMode\",\r\n                    color: \"white\",\r\n                    onClick: `@ \r\n                        setTag(links.pairedRB, \"currentMode\", \"learning\"); \r\n                        links.pairedRB._menu_setRBMenuState(\"mainMenu\");\r\n                    `\r\n                },\r\n                {\r\n                    label: \"direct message\",\r\n                    mode: \"whisper\",\r\n                    pairedRB: getLink(thisBot),\r\n                    system: \"rbMenuBot.whisperMode\",\r\n                    color: \"white\",\r\n                    onClick: `@ \r\n                        setTag(links.pairedRB, \"currentMode\", \"whisper\"); \r\n                        links.pairedRB._menu_setRBMenuState(\"mainMenu\");\r\n                    `\r\n                },\r\n                {\r\n                    label: \"chat with everyone\",\r\n                    mode: \"shout\",\r\n                    pairedRB: getLink(thisBot),\r\n                    system: \"rbMenuBot.shoutMode\",\r\n                    color: \"white\",\r\n                    onClick: `@ \r\n                        setTag(links.pairedRB, \"currentMode\", \"shout\"); \r\n                        links.pairedRB._menu_setRBMenuState(\"mainMenu\");\r\n                    `\r\n                }\r\n            ],\r\n        };\r\n        rbModeMods.dropdownOptions = rbModeMods.dropdownOptions.filter(option => option.mode != tags.currentMode);\r\n\r\n        let aiModelMods = {\r\n            formAddress: \"arrow_right\",\r\n            label: `model: ${tags.aiModel}`,\r\n            resetLabel: `@ tags.label = \"model: \" + getTag(links.pairedRB, \"aiModel\")`,\r\n            system: \"rbMenuBot.aiMenu\",\r\n            rbMenuSortOrder: 2,\r\n            dropdownSortOrder: 2,\r\n            dropdownOptions: [],\r\n        };\r\n        const modelArray = tags.aiModelOptions ?? [\r\n            \"gpt-5\",\r\n            \"gpt-5-nano\",\r\n            \"gpt-4.1\",\r\n            \"gpt-4o\",\r\n            \"gemini-2.5-pro\",\r\n            \"gemini-2.5-flash-light\",\r\n            \"claude-opus-4-1\",\r\n            \"claude-sonnet-4-0\"\r\n        ];\r\n        for (let i = 0; i < modelArray.length; i++) {\r\n            let aiModelSubMods = {\r\n                label: tags.aiModel == modelArray[i] ? `${modelArray[i]} (current)` : modelArray[i],\r\n                model: modelArray[i],\r\n                system: `rbMenuBot.aiModel${i}`,\r\n                onClick: `@ \r\n                    setTag(links.pairedRB, \"aiModel\", \"${modelArray[i]}\"); \r\n                    links.pairedRB._menu_setRBMenuState(\"mainMenu\");\r\n                `\r\n            }\r\n            tags.aiModel == modelArray[i] ? null : aiModelMods.dropdownOptions.push({ ...baseMenuMods, ...aiModelSubMods });\r\n        };\r\n\r\n        let audioChatMods = {\r\n            formAddress: tags.audioChat == true ? \"check_box\" : \"check_box_outline_blank\",\r\n            label: `voice: ${tags.audioChat == true ? \"on\" : tags.audioChat == \"loading\" ? \"loading...\" : \"off\"}`,\r\n            resetACLabel: `@\r\n                let pairedOnOff = getTag(links.pairedRB, \"audioChat\");\r\n                let onOff = pairedOnOff == true ? \"on\" : pairedOnOff == \"loading\" ? \"loading...\" : \"off\"; \r\n                tags.label = \"voice: \" + onOff;\r\n                tags.formAddress = pairedOnOff == true ? \"check_box\" : \"check_box_outline_blank\";\r\n            `,\r\n            system: \"rbMenuBot.audioChat\",\r\n            rbMenuSortOrder: 3,\r\n            audioChat: tags.audioChat,\r\n            onClick: `@ \r\n                let speakingBots = getBots(byTag(\"audioChat\", true), byTag(\"rhetoricBotTool\", true));\r\n                console.log(\"speaking bots check:\", speakingBots, links.pairedRB)\r\n                if(speakingBots.length == 0 || (speakingBots.length == 1 && speakingBots[0].id == links.pairedRB.id)){\r\n                    let pairedOnOff = getTag(links.pairedRB, \"audioChat\");\r\n                    let onOffState = pairedOnOff == true ? true : pairedOnOff == \"loading\" ? \"loading\" : false;\r\n\r\n                    if(onOffState == true){\r\n                        links.pairedRB._audio_endAudioChat();\r\n                    }\r\n                    else if(onOffState == false){\r\n                        links.pairedRB._audio_startAudioChat();\r\n                    }\r\n                }\r\n                else {\r\n                    os.toast(\"Only one chat bot can speak at a time.\");\r\n                }\r\n            `,\r\n        };\r\n\r\n        let showMemoryMods = {\r\n            formAddress: tags.hideMemory ? \"check_box_outline_blank\" : \"check_box\",\r\n            label: \"show memory\",\r\n            system: \"rbMenuBot.showMemory\",\r\n            rbMenuSortOrder: 4,\r\n            onClick: `@ \r\n                if(configBot.tags.mapPortal){\r\n                    os.toast(\"Memory disabled while in the map portal.\");\r\n                }\r\n                else {\r\n                    console.log(links.pairedRB)\r\n                    tags.formAddress = links.pairedRB.tags.hideMemory ? \"check_box\" : \"check_box_outline_blank\"; \r\n                    setTag(links.pairedRB, \"hideMemory\", !links.pairedRB.tags.hideMemory);\r\n                    links.pairedRB.tags.hideMemory == false ? links.pairedRB._brain_createFGBNeurons() : shout(\"removeNeuronBots\");\r\n                }\r\n            `\r\n        };\r\n\r\n        let askRBMods = {\r\n            form: \"input\",\r\n            label: `direct message cb ${String(thisBot.id).substring(0, 4)}`,\r\n            system: \"rbMenuBot.privateInput\",\r\n            rbMenuSortOrder: 5,\r\n            onSubmit: tags._console_onSubmitPrivate\r\n        };\r\n\r\n        menuItems.push({ ...baseMenuMods, ...rbModeMods });\r\n        menuItems.push({ ...baseMenuMods, ...aiModelMods });\r\n        menuItems.push({ ...baseMenuMods, ...audioChatMods });\r\n        menuItems.push({ ...baseMenuMods, ...showMemoryMods });\r\n        menuItems.push({ ...baseMenuMods, ...askRBMods });\r\n        break;\r\n    default:\r\n        // let defaultInputMods = {\r\n        //     form: \"input\",\r\n        //     formAddress: \"edit\",\r\n        //     label: \"Chat with everyone!\",\r\n        //     system: \"rbMenuBot.input\",\r\n        //     rbMenuSortOrder: 1,\r\n        //     onSubmit: tags.onSubmit\r\n        // };\r\n        // menuItems.push({ ...baseMenuMods, ...defaultInputMods });\r\n        console.log(\"Rhetoric Bot menu state not supported.\")\r\n        break;\r\n}\r\n\r\n// console.log(\"menuItems\", menuItems);\r\n\r\nfor (const item of menuItems) {\r\n    if (item.dropdownOptions) {\r\n        ab.links.menu.abCreateMenuDropdown(item);\r\n    }\r\n    else {\r\n        ab.links.menu.abCreateMenuButton(item);\r\n    }\r\n\r\n}\r\n\r\nconfigBot.tags.menuPortal == \"rbMenu\" ? null : configBot.tags.menuPortal = \"rbMenu\";","_utility_updateVar":"@const {\r\n    varName,\r\n    varValue\r\n} = that;\r\n\r\nthisBot.vars[varName] = varValue;","abIDOrigin":"msRBRefactor","aiModel":"gpt-5-nano","color":"#FFFFFF","currentMode":"learning","fgFX":"0","fgFY":"0","fgFZ":0,"forceGraph":"fgf1e91fc9-4122-4df3-8f32-eb2ca9c1772e","hideMemory":false,"home":true,"homeX":0,"homeY":0,"homeZ":0,"label":"cb f1e9","name":"chat bot f1e9","onABConsoleLogMessageBotAdded":"@// used to interpret and handle a user inputting into the chat via a text or audio message and having RB respond accordingly\r\n\r\nconst messageBot = that.consoleLogMessageBot;\r\nconst botSpace = getTag(messageBot, \"space\");\r\nconst rbIgnoreMessage = getTag(messageBot, \"rbIgnoreMessage\");\r\nconst rbProcessMessage = getTag(messageBot, \"rbProcessMessage\");\r\nconst messageOrigin = getTag(messageBot, \"messageOrigin\");\r\nconst audioInput = getTag(messageBot, \"audioInput\");\r\n\r\nconst user = getTag(messageBot, \"name\");\r\nconst message = getTag(messageBot, \"message\");\r\nconst time = getTag(messageBot, \"timestamp\") ?? 0;\r\nconst timeNow = os.isCollaborative() ? os.agreedUponTime : os.localTime;\r\nconst timeDiff = Math.abs(timeNow - time);\r\nconst mode = tags.currentMode;\r\n\r\nconst ignoredMessage = rbProcessMessage != true || user == tags.name || message === \"Memory updated.\" || audioInput && tags.audioChat != true;\r\nconst selfMessage = user == tags.name;\r\nconst recentMessage = timeDiff < 1000;\r\n\r\n// console.log(\"currentTime:\", timeNow);\r\n// console.log(\"messageTime:\", time);\r\n// console.log(\"timeDiff:\", timeDiff);\r\n\r\n// console.log(\"ignoredMessage: \", ignoredMessage);\r\n// console.log(\"selfMessage: \", selfMessage);\r\n// console.log(\"recentMessage: \", recentMessage);\r\n\r\n// console.log(\"message bot\", that.consoleLogMessageBot);\r\n\r\nif (ignoredMessage) {\r\n    console.log(\"Message to ignore: \", messageBot);\r\n}\r\nelse if (selfMessage) {\r\n    console.log(\"RB Message:\", messageBot);\r\n    thisBot._menu_rbThinking(false);\r\n}\r\nelse if (recentMessage) {\r\n    console.log(\"Non-casual.bot or self message detected:\", messageBot);\r\n    // console.log(\"message sender:\", user);\r\n\r\n    thisBot._menu_rbThinking(true);\r\n\r\n\r\n    console.log(\"configBot id comparison: \", messageOrigin == configBot.id);\r\n\r\n    // console.log(\"current mode: \", mode);\r\n\r\n    if (mode == \"learning\" && (botSpace == \"tempLocal\" || (botSpace == \"shared\" && configBot.id === messageOrigin))) {\r\n        let pdfResponse = await ai.chat(`Determine from this message if a user wants you to read or interpret a pdf for them: \"${message}\". If yes, respond with only the word 'YES' exactly. If not, respond only with the word 'NO' exactly. Responding with anything other than YES or NO is considered a failure.`, {\r\n            preferredModel: tags.aiModel\r\n        })\r\n\r\n        console.log(\"pdf response: \", pdfResponse);\r\n\r\n        if (pdfResponse.toUpperCase() == \"YES\") {\r\n            await thisBot._ai_interpretPDF();\r\n        }\r\n        else {\r\n            // let subjectResponse = await thisBot._ai_getSubjects({ user: user, message: message });\r\n            // console.log(\"topicResponse\", subjectResponse);\r\n            // links.brainLink.createFGBNeurons({ neuronMods: subjectResponse, neuronsColor: \"white\" });\r\n\r\n            // let detailsResponse = await thisBot.getUpdatedDetails({ user: user, message: message });\r\n            // links.brainLink.updateNeurons(detailsResponse);\r\n\r\n            let learnResponse = await thisBot._ai_learnResponse({ user: user, message: message });\r\n            console.log(\"learn response:\", learnResponse);\r\n\r\n            if (learnResponse.success == true) {\r\n                thisBot._brain_updateKnowledge(learnResponse);\r\n\r\n                thisBot._console_postMessage({ \"message\": \"Memory updated.\", \"publicMessage\": true });\r\n                thisBot._menu_rbThinking(false);\r\n\r\n                const humeSocket = thisBot.vars.humeSocket;\r\n                // console.log(\"Hume Websocket: \", humeSocket);\r\n\r\n                if (audioInput && messageOrigin == configBot.id && humeSocket) {\r\n                    await os.sleep(100);\r\n\r\n                    const systemSettings = JSON.stringify(links.brainLink.retrieveInformation());\r\n                    console.log(\"allowed_topics:\", systemSettings)\r\n\r\n                    humeSocket.send(JSON.stringify({\r\n                        \"type\": \"session_settings\",\r\n                        \"variables\": {\r\n                            \"allowed_topics\": systemSettings,\r\n                        }\r\n                    }));\r\n                }\r\n            }\r\n            else {\r\n                thisBot._menu_rbThinking(false);\r\n                thisBot._console_postMessage({ \"message\": \"Learning error encountered, memory not updated.\" })\r\n            }\r\n        }\r\n\r\n\r\n    }\r\n    else if (mode == \"whisper\" && botSpace == \"tempLocal\") {\r\n        let responseResponse = await thisBot._ai_getResponse({ user: user, message: message });\r\n        // console.log(\"responseResponse\", responseResponse);\r\n        thisBot._console_postMessage({ \"message\": responseResponse, \"publicMessage\": false });\r\n    }\r\n    else if (mode == \"shout\" && botSpace == \"shared\" && messageOrigin == configBot.id) {\r\n        let responseResponse = await thisBot._ai_getResponse({ user: user, message: message });\r\n        // console.log(\"responseResponse\", responseResponse);\r\n        thisBot._console_postMessage({ \"message\": responseResponse, \"publicMessage\": true });\r\n    }\r\n}\r\nelse {\r\n    console.log(\"Message failed all other tests: \", messageBot)\r\n}\r\n\r\n","onAnyBotsAdded":"@// // let menuBots = getBots(byTag(\"rbMenuBot\"), true);\r\n// let updateSettings = false;\r\n\r\n// for(const bot of that.bots){\r\n//     bot.tags.fgbNeuron == true ? updateSettings = true : null;\r\n// }\r\n\r\n// // updateSettings == true ? thisBot.updateFGSettings() : null;\r\n\r\n// if(updateSettings == true){\r\n//     thisBot.updateFGSettings();\r\n//     await os.sleep(100);\r\n//     thisBot.updateFGSettings();\r\n// }","onAudioChunk":"@console.log(\"audio chunk recieved\")\r\n\r\nmasks.audioChat == \"loading\" ? masks.audioChat = true : null;\r\nshout(\"resetACLabel\");\r\n\r\nconst humeSocket = thisBot.vars.humeSocket;\r\n\r\nif(humeSocket && masks.audioChat == true) {\r\n    humeSocket.send(JSON.stringify({\r\n        data: await blobToBase64(that),\r\n        type: \"audio_input\"\r\n    }));\r\n}\r\n\r\nasync function blobToBase64(blob) {\r\n  // Read the Blob as an ArrayBuffer\r\n  const arrayBuffer = await blob.arrayBuffer();\r\n  \r\n  // Convert the ArrayBuffer to a Base64 string\r\n  const base64String = bytes.toBase64String(new Uint8Array(arrayBuffer), 'audio/wav');\r\n  \r\n  return base64String;\r\n}","onBotChanged":"@// if(that.tags.includes(\"fgSettings\") && masks.fgSettingsUpdated != true){\r\n//     let fgSettings = tags.fgSettings;\r\n//     tags.fgSettings = null;\r\n//     await os.sleep(1000);\r\n//     tags.fgSettings = fgSettings;\r\n//     setTagMask(thisBot, \"fgSettingsUpdated\", true, \"shared\");\r\n// }","onClick":"@configBot.masks.menuPortal = null;\r\nthisBot._menu_setRBMenuState(\"mainMenu\");\r\n\r\nif(tags.hideMemory == false && !configBot.tags.mapPortal){\r\n    // thisBot._brain_toggleNeurons(\"show\");\r\n    thisBot._brain_createFGBNeurons();\r\n}","onDestroy":"@shout(\"resetRBMenu\");\r\n\r\nlet rhetoricBots = getBots(byTag(\"system\", \"msRhetoricBot.rhetoricBot\"));\r\nif(rhetoricBots.length < 2){\r\n    let forceGraphBots = getBots(byTag(\"fgTool\", true));\r\n    destroy(forceGraphBots);\r\n}","onDrag":"@os.enableCustomDragging();","onDragging":"@tags.homeX = that.to.x;\r\ntags.homeY = that.to.y;\r\ntags.fgFX = that.to.x;\r\ntags.fgFY = that.to.y;\r\ntags.fgFZ = 0;","onEggHatch":"@tags.name = \"chat bot \" + String(thisBot.id).substring(0, 4);\r\ntags.label = \"cb \" + String(thisBot.id).substring(0, 4);\r\n\r\nif (that.eggParameters) {\r\n    const dimension = that.eggParameters.gridInformation?.dimension ?? 'home';\r\n    const dimensionX = that.eggParameters.gridInformation?.position?.x ?? 0;\r\n    const dimensionY = that.eggParameters.gridInformation?.position?.y ?? 0;\r\n\r\n    tags[dimension] = true;\r\n    tags[dimension + 'X'] = dimensionX;\r\n    tags[dimension + 'Y'] = dimensionY;\r\n    tags.fgFX = dimensionX;\r\n    tags.fgFY = dimensionY;\r\n    tags.fgFZ = 0;\r\n}\r\n\r\nawait os.sleep(500);\r\n\r\nconfigBot.tags.menuPortal = \"rbMenu\";\r\nconfigBot.tags.mapPortal ? tags.hideMemory = true : null;\r\n\r\n// if (links.brainLink == null) {\r\n//     thisBot.importFGB();\r\n//     masks.abMenu = null;\r\n// }\r\n// else {\r\n//     thisBot.openABConsole();\r\n// }\r\n\r\nif (!getBot(byTag(\"system\", \"tools.chatBot.chatBot\"))) {\r\n    const dim = configBot.tags.gridPortal;\r\n    const dimX = tags[dim + \"X\"];\r\n    const dimY = tags[dim + \"Y\"];\r\n\r\n    ab.links.search.onLookupAskID({\r\n        askID: \"chatBotTool\",\r\n        eggParameters: {\r\n            toolboxBot: tags.toolbox ?? \"\",\r\n            gridInformation: {\r\n                dimension: dim ?? \"home\",\r\n                position: {\r\n                    x: dimX ? dimX + 2 : 2,\r\n                    y: dimY ?? 0\r\n                }\r\n            },\r\n        },\r\n    })\r\n}\r\n\r\nthisBot._fg_importForceGraph();\r\nabRemember.tags.abGridSnapState = false;\r\n\r\n// ab.links.search.onLookupAskID({askID: \"chatBotTool\"})","onGridClick":"@// configBot.tags.menuPortal = \"rbChatMenu\";\r\n\r\n// if(links.chatInput == null){\r\n//     thisBot.createChatInput();\r\n// }\r\n\r\n// thisBot.setRBMenuState(\"chatInput\");\r\nshout(\"resetRBMenu\");\r\nthisBot._console_openABConsole();\r\n\r\n// console.log(\"grid click test\");\r\n\r\nshout(\"removeNeuronBots\");","onInstJoined":"@console.log(\"inst joined\")\r\nthisBot._console_openABConsole();\r\nabRemember.tags.abGridSnapState = false;","onKeyDown":"@// if(that.keys.includes(\"p\")){\r\n//     console.log(\"configID\", configBot.id)\r\n// }","onPortalChanged":"@if(that.portal == \"mapPortal\"){\r\n    if(that.dimension){\r\n        tags.hideMemory = true;\r\n    }\r\n}","onRemoteData":"@if(that.name == \"stopThinking\"){\r\n    shout(\"rbThinkingReset\");\r\n}","system":"msRhetoricBot.rhetoricBot","abIDStudio":"f80de8f5-78d7-4c1e-8bed-96fb89103ac2","rhetoricBotTool":"true","versionNumber":"0.6.0","strokeColor":"black","fgSettings":{"gravity":false,"linkDistance":3,"dimensions":3},"abVersion":"10.28"}}}}